<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://bateman.io/images/favicon.png" />
<title>Sidewalk Following Robot | Sam Bateman&#39;s Personal Website</title>
<meta name="title" content="Sidewalk Following Robot" />
<meta name="description" content="A Sidewalk Following robot using Deeplab v3 segmentation." />
<meta name="keywords" content="robotics,deep learning," />


<meta property="og:title" content="Sidewalk Following Robot" />
<meta property="og:description" content="A Sidewalk Following robot using Deeplab v3 segmentation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bateman.io/project/sidewalk_robot/" />
<meta property="og:image" content="https://bateman.io/images/share.png"/>
<meta property="article:published_time" content="2019-12-24T23:10:41-07:00" />
<meta property="article:modified_time" content="2019-12-24T23:10:41-07:00" /><meta property="og:site_name" content="Sam Bateman&#39;s Personal Website" />



<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://bateman.io/images/share.png"/>

<meta name="twitter:title" content="Sidewalk Following Robot"/>
<meta name="twitter:description" content="A Sidewalk Following robot using Deeplab v3 segmentation."/>



<meta itemprop="name" content="Sidewalk Following Robot">
<meta itemprop="description" content="A Sidewalk Following robot using Deeplab v3 segmentation.">
<meta itemprop="datePublished" content="2019-12-24T23:10:41-07:00" />
<meta itemprop="dateModified" content="2019-12-24T23:10:41-07:00" />
<meta itemprop="wordCount" content="466">
<meta itemprop="image" content="https://bateman.io/images/share.png"/>



<meta itemprop="keywords" content="robotics,deep learning," />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>
</head>

<body>
  <header><a href="/" class="title">
  <h2>Sam Bateman&#39;s Personal Website</h2>
</a>
<nav><a href="/">Home</a>

<a href="/cv.pdf">CV</a>

<a href="/post/">Blog</a>

<a href="/project/">Projects</a>


</nav>
<h2>Sidewalk Following Robot</h2>
</header>
  <main>

<content>
  
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/I7hWo7P2S24" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>This project is a robot which, for extended distances, can follow and map sidewalk networks in a <a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">global, UTM coordinate frame</a> while avoiding bikes, pedestrians and small ground vehicles.</p>
<p>Our platform is a <a href="https://clearpathrobotics.com/jackal-small-unmanned-ground-vehicle/">Clearpath Jackal</a>, again, utilizing a <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/">Nvidia Xavier</a> for perception, 2x <a href="https://www.intelrealsense.com/depth-camera-d435/">Intel Realsense D435</a> which are frame synced and a <a href="https://www.intel.com/content/www/us/en/products/boards-kits/nuc.html">Intel NUC</a> for control and planning.</p>
<p>We use <a href="https://github.com/nyoki-mtl/pytorch-segmentation">Deeplab v3</a> with a <a href="https://arxiv.org/abs/1704.04861">Mobile Net</a> backbone trained on <a href="https://www.cityscapes-dataset.com/">Cityscapes</a> for real time segmentation (25-30fps) running with 16bit floating point mode using <a href="https://developer.nvidia.com/tensorrt">TensorRT</a> while doing <a href="https://github.com/raulmur/ORB_SLAM2">RGB-D ORB_SLAM2</a> or <a href="https://github.com/JakobEngel/dso">DSO</a> depending on the sequence for mapping and pose estimates.  There is a strong prior on being on a road from the dataset, so we have to use both road and sidewalk masks to correctly segment the sidewalk (plus CU Boulder sidewalks are very strange compared to the average sidewalk/road). We then do morphological closing and erosion on the resulting segmentation of the sidewalk while dropping any of the mask that is too far away on the horizon to be relevant in the near term feedback controller. We then take a centroid of the resulting sidewalk mask, which we feed into a Kalman filter to smooth the output of the segmentation and deal with frames where we detect no segmentations or just very noisy segmentations. All of this is needed because the network is extremely unreliable on campus because of its expectation of a scene to be viewed from a road and a higher vantage point, neither of which we are doing. From here, we do a simple feedback controller on the heading provided by filtering over our SLAM estimate and our INS fix to change heading to center the centroid in the image to effectively follow the &ldquo;gap&rdquo; of the high intensity region of the segmentation surrounded by nontraversable areas. This ends up being useful because humans, bikes and cars are also not traversable, and thus, the robot will actively avoid these other objects as a side effect of this design.</p>
<p>This functions quite well given optimal lighting conditions, however it struggles to segment all traversable area effectively when long shadows (common in the winter in afternoon in Colorado) are drawn across the sidewalk, causing it to incorrectly change direction and sometimes lose the sidewalk completely. It also struggles with sun glare which is not present in the dataset, causing it to lose its segmentation, and further its heading. The kalman filter carries it through some of these, but it can only do so well. This approach also struggles with junctions, because it assumes this is just a very large sidewalk, to explore these branching paths, we would have to implement a control strategy using our map.</p>
<p>This project is for CU Boulders CSCI 7000: Autonomous Vehicle Challange with <a href="http://www.ristoffer.ch/">Professor Heckman</a> in conjunction with the <a href="https://arpg.github.io/">ARPG Lab</a>.</p>

</content>
<p>
  
  <a href="https://bateman.io/blog/robotics/">#Robotics</a>
  
  <a href="https://bateman.io/blog/deep-learning/">#deep learning</a>
  
</p>

  </main>
  <footer>
</footer>

    
</body>

</html>
