<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>robotics on Sam Bateman&#39;s Personal Website</title>
    <link>https://bateman.io/tags/robotics/</link>
    <description>Recent content in robotics on Sam Bateman&#39;s Personal Website</description>
    <ttl>1440</ttl>
    <generator>Hugo 0.68.3</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 10 Jan 2021 22:06:56 UT</lastBuildDate>
    <atom:link href="https://bateman.io/tags/robotics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>IROS 2020 - Better Together: Online Probabilistic Clique Change Detection in 3D Landmark-Based Maps</title>
      <link>https://bateman.io/project/joint-clique-filter/</link>
      <pubDate>Sun, 01 Nov 2020 02:34:04 UT</pubDate>
      <dc:creator>Sam Bateman</dc:creator>
      <guid>https://bateman.io/project/joint-clique-filter/</guid>
      <description>In this paper, we expanded on the work of David Rosen and Fernando Nobre, developing a new method for landmark persistence change detection well suited for the challenges of complicated 3D worlds which wasn&amp;rsquo;t previously addressed by prior work. Our approach allows for the use of semantic priors on inclusing of features into a single semantic set, allowing for what amounts to joint object persistence estimation in the real world without explicitly tracking any objects.</description>
      <category domain="https://bateman.io/categories/robotics">Robotics</category>
      <content:encoded><![CDATA[   In this paper, we expanded on the work of David Rosen and Fernando Nobre, developing a new method for landmark persistence change detection well suited for the challenges of complicated 3D worlds which wasn&amp;rsquo;t previously addressed by prior work. Our approach allows for the use of semantic priors on inclusing of features into a single semantic set, allowing for what amounts to joint object persistence estimation in the real world without explicitly tracking any objects. The idea is that this could be used alone or in tandem with a traditional perception pipeline to allow feature based SLAM systems to operate long term deployments in a number of dynamic and semi-static environments which currently cause drift or failure of the current state of the art.
For the full paper we submitted to IROS and all the gory details, see our Arxiv Paper.
]]></content:encoded>
    </item>
    <item>
      <title>Undergrad Thesis - An Exploration of Algorithms Enabling a Semantics-Aware Class-Based Probablistic Dynamic SLAM</title>
      <link>https://bateman.io/project/undergrad-thesis/</link>
      <pubDate>Mon, 04 May 2020 21:39:21 UT</pubDate>
      <dc:creator>Sam Bateman</dc:creator>
      <guid>https://bateman.io/project/undergrad-thesis/</guid>
      <description>This thesis describes the work that I performed persuant to recieving my undergraduate degree at CU Boulder. This thesis was advised by the exceptional Christoffer Heckman. In it, we explore utilizing a semantics aware clique-based persistence filter to handle non-static elements in a environment. Further, multi-agent tracking systems are reviewed and explored to provide semantic and panoptic segmentation of an environment to track persistance statistics of objects in a world online.</description>
      <category domain="https://bateman.io/categories/robotics">Robotics</category>
      <content:encoded><![CDATA[This thesis describes the work that I performed persuant to recieving my undergraduate degree at CU Boulder. This thesis was advised by the exceptional Christoffer Heckman. In it, we explore utilizing a semantics aware clique-based persistence filter to handle non-static elements in a environment. Further, multi-agent tracking systems are reviewed and explored to provide semantic and panoptic segmentation of an environment to track persistance statistics of objects in a world online. These are used with the language of Surivival Analysis to provide adaptive, high quality survival time priors to the persitence filter. Finally, usage of gaussian processes to estimate survival time prior distribution online is suggested using the devised framework, however, time restricted the exploration of the final goal of the paper.
The full thesis can be found here.
]]></content:encoded>
    </item>
    <item>
      <title>Sidewalk Following Robot</title>
      <link>https://bateman.io/project/sidewalk_robot/</link>
      <pubDate>Wed, 25 Dec 2019 06:10:41 UT</pubDate>
      <dc:creator>Sam Bateman</dc:creator>
      <guid>https://bateman.io/project/sidewalk_robot/</guid>
      <description>This project is a robot which, for extended distances, can follow and map sidewalk networks in a global, UTM coordinate frame while avoiding bikes, pedestrians and small ground vehicles.
Our platform is a Clearpath Jackal, again, utilizing a Nvidia Xavier for perception, 2x Intel Realsense D435 which are frame synced and a Intel NUC for control and planning.
We use Deeplab v3 with a Mobile Net backbone trained on Cityscapes for real time segmentation (25-30fps) running with 16bit floating point mode using TensorRT while doing RGB-D ORB_SLAM2 or DSO depending on the sequence for mapping and pose estimates.</description>
      <category domain="https://bateman.io/categories/robotics">Robotics</category>
      <content:encoded><![CDATA[   This project is a robot which, for extended distances, can follow and map sidewalk networks in a global, UTM coordinate frame while avoiding bikes, pedestrians and small ground vehicles.
Our platform is a Clearpath Jackal, again, utilizing a Nvidia Xavier for perception, 2x Intel Realsense D435 which are frame synced and a Intel NUC for control and planning.
We use Deeplab v3 with a Mobile Net backbone trained on Cityscapes for real time segmentation (25-30fps) running with 16bit floating point mode using TensorRT while doing RGB-D ORB_SLAM2 or DSO depending on the sequence for mapping and pose estimates. There is a strong prior on being on a road from the dataset, so we have to use both road and sidewalk masks to correctly segment the sidewalk (plus CU Boulder sidewalks are very strange compared to the average sidewalk/road). We then do morphological closing and erosion on the resulting segmentation of the sidewalk while dropping any of the mask that is too far away on the horizon to be relevant in the near term feedback controller. We then take a centroid of the resulting sidewalk mask, which we feed into a Kalman filter to smooth the output of the segmentation and deal with frames where we detect no segmentations or just very noisy segmentations. All of this is needed because the network is extremely unreliable on campus because of its expectation of a scene to be viewed from a road and a higher vantage point, neither of which we are doing. From here, we do a simple feedback controller on the heading provided by filtering over our SLAM estimate and our INS fix to change heading to center the centroid in the image to effectively follow the &amp;ldquo;gap&amp;rdquo; of the high intensity region of the segmentation surrounded by nontraversable areas. This ends up being useful because humans, bikes and cars are also not traversable, and thus, the robot will actively avoid these other objects as a side effect of this design.
This functions quite well given optimal lighting conditions, however it struggles to segment all traversable area effectively when long shadows (common in the winter in afternoon in Colorado) are drawn across the sidewalk, causing it to incorrectly change direction and sometimes lose the sidewalk completely. It also struggles with sun glare which is not present in the dataset, causing it to lose its segmentation, and further its heading. The kalman filter carries it through some of these, but it can only do so well. This approach also struggles with junctions, because it assumes this is just a very large sidewalk, to explore these branching paths, we would have to implement a control strategy using our map.
This project is for CU Boulders CSCI 7000: Autonomous Vehicle Challange with Professor Heckman in conjunction with the ARPG Lab.
]]></content:encoded>
    </item>
  </channel>
</rss>
